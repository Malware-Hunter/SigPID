{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimeto SIGPid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install apyori\n",
    "!pip install mlxtend  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import sklearn\n",
    "import timeit\n",
    "import os, sys, stat\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix,plot_confusion_matrix, plot_roc_curve\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from apyori import apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cria a extrutura de diret√≥rios do experimento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joner\\OneDrive\\Documentos\\ProjetoMotorola\\SigPID\\Experimento\n",
      "/MLDP/PIS_PRNR/SVM_Resultados : Existentes\n",
      "/MLDP/PIS_PRNR/SVM_Resultados : Existentes\n",
      "/MLDP/PIS_SPR/SVM_Resultados : Existentes\n",
      "/MLDP/PMAR/SVM_Resultados : Existentes\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "print(cwd)\n",
    "#Resultados das m√©tricas e tempos de execu√ß√£o\n",
    "directory = \"SVM_Resultados\"\n",
    "parent_dir = \"/MLDP/PIS_PRNR/\"\n",
    "parent_dir1 = \"/MLDP/PIS_PRNR/\"\n",
    "parent_dir2 = \"/MLDP/PIS_SPR/\"\n",
    "parent_dir3 = \"/MLDP/PMAR/\"\n",
    "path = os.path.join(parent_dir, directory)\n",
    "if os.path.exists(cwd+path):\n",
    "    print(path + ' : Existentes')\n",
    "else:\n",
    "    os.makedirs(cwd+path)\n",
    "    print(\"Diret√≥rio'%s' criado\" %directory)\n",
    "\n",
    "path1 = os.path.join(parent_dir1, directory)\n",
    "if os.path.exists(cwd+path1):\n",
    "    print(path1 + ' : Existentes')\n",
    "else:\n",
    "    os.makedirs(cwd+path1)\n",
    "    print(\"Diret√≥rio'%s' criado\" %directory)\n",
    "\n",
    "path2 = os.path.join(parent_dir2, directory)\n",
    "if os.path.exists(cwd+path2):\n",
    "    print(path2 + ' : Existentes')\n",
    "else:\n",
    "    os.makedirs(cwd+path2)\n",
    "    print(\"Diret√≥rio'%s' criado\" %directory)\n",
    "\n",
    "path3 = os.path.join(parent_dir3, directory)\n",
    "if os.path.exists(cwd+path3):\n",
    "    print(path3 + ' : Existentes')\n",
    "else:\n",
    "    os.makedirs(cwd+path3)\n",
    "    print(\"Diret√≥rio'%s' criado\" %directory) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carrega o subset com 113 permiss√µes oriundas do Drebin_215"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "permissions_table = pd.read_csv('datasets/DrebinDatasetPermissoes.csv', encoding = 'utf8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A abordagem SigPID opera em duas matrizes,\n",
    "M e B. M representa uma lista de permiss√µes usadas por amostras de\n",
    "malware e B representa uma lista de permiss√µes usadas por\n",
    "aplicativos benignos. Sendo que 1 representa o conjuto dos Malwares e 0 o conjunto dos Benignos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "values=[1]\n",
    "M = permissions_table[permissions_table['class'].isin(values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "values=[0]\n",
    "B = permissions_table[permissions_table['class'].isin(values)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Para equilibrar as duas matrizes, os autores utilizaram a Equa√ß√£o abaixo\n",
    "para calcular o suporte de cada permiss√£o no conjunto\n",
    "de dados maior e, em seguida, dimencionar proporcionalmente o\n",
    "suporte correspondente para corresponder ao do conjunto de dados menor.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$S_{b}(P_{j})=\\frac{\\sum_{i}{Bij}}{Size(_{Bj})}*Size(_{Mj})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ùëÜùëè(ùëÉùëó)\n",
    "def S_B(j):\n",
    "    sigmaBij = B.sum(axis = 0, skipna = True)[j]\n",
    "    sizeBj = B.shape[0]\n",
    "    sizeMj = M.shape[0]\n",
    "    return (sigmaBij/sizeBj)*sizeMj\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pj onde j representa as permiss√£o, e Sb (Pj) representa o suporte de j a permiss√£o na matriz B. PRNR pode ent√£o\n",
    "ser implementado usando a Equa√ß√£o abaixo.**\n",
    "Na f√≥rmula abaixo, R (Pj) representa a taxa de j\n",
    "a permiss√£o. O resultado de R (Pj) tem um valor que varia entre\n",
    "[-1, 1]. \n",
    "* Se R (Pj) = 1, isso significa que a permiss√£o Pj √© apenas\n",
    "  usado em um conjunto de dados malicioso, que √© uma permiss√£o de alto risco.\n",
    "* Se R (Pj) = -1, isso significa que a permiss√£o Pj s√≥ √© usada em\n",
    "  conjunto de dados benigno, que √© uma permiss√£o de baixo risco.\n",
    "* Se R (Pj) = 0,isso significa que Pj tem muito pouco impacto na detec√ß√£o de malware."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ R_(P_{j})=\\frac{\\sum_{i}{Mij}-S_{b}(P_{j})}{\\sum_{i}{Mij}+S_{b}(P_{j})}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PRNR(j):\n",
    "    sigmaMij = M.sum(axis = 0, skipna = True)[j]\n",
    "    S_Bj = S_B(j)\n",
    "    #print(str(j)+\",\"+str((sigmaMij-S_Bj)/(sigmaMij+S_Bj)))\n",
    "    return (sigmaMij-S_Bj)/(sigmaMij+S_Bj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcula o rank da lista de Benignos e salva em TXT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  csv\n",
    "# variavel que armazena uma lista de permiss√µes\n",
    "# melhorar a gera√ß√£o do arquivo para remover sujeiras como (\" e outros)\n",
    "permissoes =  []\n",
    "perm = B.drop(columns=['class','android.permission.INTERNET'])\n",
    "\n",
    "for per in perm:\n",
    "    permissions_PRNR_ranking = PRNR(per)\n",
    "    if permissions_PRNR_ranking !=0:\n",
    "        permissoes.append(per+','+str(permissions_PRNR_ranking))\n",
    "        #print(per+','+str(permissions_PRNR_ranking))\n",
    "        per_B= np.concatenate((permissoes,'class'), axis=None)\n",
    "        with open(\"datasets/Lista_B_PRNR.txt\",\"w\") as f:\n",
    "            wr = csv.writer(f,delimiter=\"\\n\")\n",
    "            wr.writerow(list(per_B))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcula o suporte da lista de Malwares e salva em TXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import  csv\n",
    "# variavel que armazena uma lista de permiss√µes\n",
    "permissoes =  []\n",
    "perm = M.drop(columns=['class','android.permission.INTERNET'])\n",
    "for per in perm:\n",
    "    permissions_PRNR_ranking = PRNR(per)\n",
    "    if permissions_PRNR_ranking !=0:  \n",
    "        permissoes.append(per+','+str(permissions_PRNR_ranking))\n",
    "        #print(per+','+str(permissions_PRNR_ranking))\n",
    "        per_M= np.concatenate((permissoes,'class'), axis=None)\n",
    "        with open(\"datasets/Lista_M_PRNR.txt\",\"w\") as f:\n",
    "            wr = csv.writer(f,delimiter=\"\\n\")\n",
    "            wr.writerow(list(per_M))\n",
    "\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplica PIS sobre o PRNR\n",
    "**Anteriormente criamos 2 listas(benignos e malwares) com seu devido suportes.\n",
    "Agora carregamos estas listas e colocamos benignos em ordem crecente e malwares em ordem decrecente**\n",
    "**Ent√£o, escolhemos as tr√™s principais permiss√µes em ambas as listas para construir\n",
    "sistema de detec√ß√£o de malware. Repetimos o processo novamente. A cada incremento √© gerado um subset e um log das permiss√µes selecionadas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ de permiss√µes  6\n",
      "N¬∫ de permiss√µes  12\n",
      "N¬∫ de permiss√µes  18\n",
      "N¬∫ de permiss√µes  24\n",
      "N¬∫ de permiss√µes  30\n",
      "N¬∫ de permiss√µes  36\n",
      "N¬∫ de permiss√µes  42\n",
      "N¬∫ de permiss√µes  48\n",
      "N¬∫ de permiss√µes  54\n",
      "N¬∫ de permiss√µes  60\n",
      "N¬∫ de permiss√µes  66\n",
      "N¬∫ de permiss√µes  72\n",
      "N¬∫ de permiss√µes  78\n",
      "N¬∫ de permiss√µes  84\n",
      "N¬∫ de permiss√µes  90\n",
      "N¬∫ de permiss√µes  96\n",
      "N¬∫ de permiss√µes  102\n",
      "N¬∫ de permiss√µes  108\n",
      "N¬∫ de permiss√µes  112\n"
     ]
    }
   ],
   "source": [
    "# Carrega a lista de suporte gerada anteriormente e ordena os malwares em ordem decrecente\n",
    "#criar um contador para ir incrementando a cada execu√ß√£o(6,12,18...)\n",
    "colnames = ['Permiss√£o','rank']\n",
    "malwares = pd.read_csv('datasets/Lista_M_PRNR.txt', sep = \",\" , names = colnames)\n",
    "malwares[\"rank\"] = pd.to_numeric(malwares[\"rank\"])\n",
    "malwaresort = malwares.sort_values(by=['rank'],ascending=[False])\n",
    "#aqui defini o incremento ex(head(3) para os 3 primeiros)\n",
    "#malware_increment = malwaresort['Permiss√£o'].head(3).values\n",
    "\n",
    "# Carrega a lista de suporte gerada anteriormente e ordena os benignos em ordem crecente\n",
    "benignos = df_PRNR_txt = pd.read_csv('datasets/Lista_B_PRNR.txt', sep=\",\" , names = colnames)\n",
    "benignos[\"rank\"] = pd.to_numeric(benignos[\"rank\"])\n",
    "benignosort = benignos.sort_values(by=['rank'],ascending=[True])\n",
    "#aqui defini o incremento ex(head(3) para os 3 primeiros\n",
    "#benigno_increment= benignosort['Permiss√£o'].head(3).values\n",
    "\n",
    "#usando while para gerar o incremento com top 3 valores de cada lista\n",
    "counter=3\n",
    "while counter < len(permissoes)/2+2:\n",
    "    malware_increment = malwaresort['Permiss√£o'].head(counter).values\n",
    "    benigno_increment= benignosort['Permiss√£o'].head(counter).values\n",
    "    # aqui eu crio o arquivo que possui as permiss√µes selecionadas de cada lista \n",
    "    PIS =  np.concatenate((benigno_increment, malware_increment,'class'), axis=None)\n",
    "    with open(\"MLDP/PIS_PRNR/PIS_PRNR\"+str(counter*2)+\".txt\",\"w\") as f:\n",
    "                wr = csv.writer(f,delimiter=\",\")\n",
    "                wr.writerow(PIS)\n",
    "    \n",
    "                \n",
    "    #Aqui √© carregado as permiss√µes geradas no passo anterior e cria os subsets de cada incremento\n",
    "    # esses subsets s√£o derivados da baseline que possui 113 permiss√µes\n",
    "    df_permi_drebim = pd.read_csv('datasets/DrebinDatasetPermissoes.csv')\n",
    "    df_PRNR_txt = pd.read_csv('MLDP/PIS_PRNR/PIS_PRNR'+str(counter*2)+'.txt')\n",
    "    df_filtrado2 = df_permi_drebim.reindex(columns=[*df_PRNR_txt])\n",
    "    df_PRNR=df_filtrado2.dropna(axis=1)\n",
    "    #Subset em csv \n",
    "    df_PRNR.to_csv(\"MLDP/PIS_PRNR/PIS_PRNR\"+str(counter*2)+\".csv\", index=False)\n",
    "\n",
    "    df_PRNR.isna().values.any()\n",
    "    print('N¬∫ de permiss√µes ',len(df_PRNR.columns)-1)\n",
    "    \n",
    "    counter = counter +3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PIS = Aplicar SVM com as top 3 de cada lista e vai incrementando at√© testar todos os subsets gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(counter):\n",
    "    with open('MLDP/PIS_PRNR/SVM_Resultados/tempos_PIS_PRNR.txt', 'a') as arquivo:\n",
    "    #agora basta ir mudando o nome do arquivo para o gerado nos passos anteriores\n",
    "        dataset_df = pd.read_csv('MLDP/PIS_PRNR/PIS_PRNR'+str(counter)+'.csv', encoding = 'utf8')\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        state = np.random.randint(100)\n",
    "        Y = dataset_df['class']\n",
    "        X = dataset_df.drop(['class'], axis=1)\n",
    "        # dividir entre conjuntos de treino e teste\n",
    "        #note que \"test_size\" √© o tamanho da amostra de teste\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify=Y, test_size=0.3,random_state=1)\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=1)\n",
    "\n",
    "        from sklearn.svm import SVC\n",
    "        svm = SVC(kernel='linear', C=1.0, random_state=1)\n",
    "        svm.fit(X_train,y_train)\n",
    "\n",
    "        # r√≥tulos de predi√ß√£o para X_test\n",
    "        y_pred=svm.predict(X_test)\n",
    "\n",
    "        #Metricas\n",
    "        \"\"\"\n",
    "        tn = Verdadeiro Negativo uma previs√£o correta prevista como benigno\n",
    "\n",
    "        fp = Falso Positivo um falso alarme um benigno previsto como malicioso\n",
    "\n",
    "        tp = Verdadeiro Positivo uma previs√£o correta (malicioso)\n",
    "\n",
    "        fn = Falso Negativo um r√≥tulo malicioso previsto como benigno\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        elapsed = timeit.default_timer() - start_time\n",
    "        from sklearn import metrics \n",
    "        print('SVM_tempo',elapsed, file=arquivo)\n",
    "        # A cada execu√ß√£o salva os resultados em um arquivo chamado metricasSVM.txt, mudar conforme necessidade\n",
    "        with open('MLDP/PIS_PRNR/SVM_Resultados/metricas_PIS_PRNR.txt', 'a') as arquivo1:\n",
    "            #ideal √© automatizar um contador para cada incremento\n",
    "            print('PIS_PRNR'+str(counter), file=arquivo1)\n",
    "            # Precis√£o do modelo: com que frequ√™ncia o classificador est√° correto?\n",
    "            print(\"Acur√°cia:\",metrics.accuracy_score(y_test, y_pred), file=arquivo1)\n",
    "            # Precis√£o do modelo: qual porcentagem de r√≥tulos positivos est√° correta?\n",
    "            print(\"Precis√£o:\",metrics.precision_score(y_test, y_pred), file=arquivo1)\n",
    "            # Model Recall: qual porcentagem de tuplas positivas s√£o rotuladas como tal?\n",
    "            print(\"Recall:\",metrics.recall_score(y_test, y_pred), file=arquivo1)\n",
    "            # \n",
    "            print(\"F1_Score:\",metrics.f1_score(y_test, y_pred), file=arquivo1)\n",
    "            # FPR: porcentagem de falso positivo de todos os negativos nos dados\n",
    "            print(\"FPR:\",fp/(fp+tn), file=arquivo1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Talvez melhorar esse incremento para algo mais elegante :)\n",
    "counter=6\n",
    "while counter <= len(permissoes)+2:\n",
    "    SVM(counter)\n",
    "    counter = counter +6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot PIS+PRNR\n",
    "**O decaimento da acur√°cia ocoreu ap√≥s 108 permiss√µes, ent√£o 108 s√£o as permiss√µes selecionadas como podemos ver no gr√°fico abaixo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](MLDP/PIS_PRNR/SVM_Resultados/DesempenhoPRNR.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatizar o grafico para pegar o Max valor\n",
    "#df = pd.read_csv('MLDP/PIS_PRNR/SVM_Resultados/metricas_PIS_PRNR1.txt', sep=\" \",header=None)\n",
    "#print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## analiar os dados e carregar o subset com as permiss√µes selecionadas no passo PRNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#carregar o subset gerado no passo anterior\n",
    "df_PRNR = pd.read_csv(\"MLDP/PIS_PRNR/PIS_PRNR108.csv\", encoding = 'utf8')\n",
    "df_PRNR.shape[1]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_PRNR1 = df_PRNR.drop(columns=['class'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM(subset,counter):\n",
    "    with open('MLDP/PIS_SPR/SVM_Resultados/tempos_PIS_SPR.txt', 'a') as arquivo:\n",
    "\n",
    "        start_time = timeit.default_timer()\n",
    "\n",
    "        state = np.random.randint(100)\n",
    "        Y = subset['class']\n",
    "        X = subset.drop(['class'], axis=1)\n",
    "        # dividir entre conjuntos de treino e teste\n",
    "        #note que \"test_size\" √© o tamanho da amostra de teste\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, stratify=Y, test_size=0.3,random_state=1)\n",
    "        #usar k-floud\n",
    "        #n_estimators=100,max_depth=50\n",
    "        X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=1)\n",
    "\n",
    "        from sklearn.svm import SVC\n",
    "        svm = SVC(kernel='linear', C=1.0, random_state=1)\n",
    "        svm.fit(X_train,y_train)\n",
    "\n",
    "        # r√≥tulos de predi√ß√£o para X_test\n",
    "        y_pred=svm.predict(X_test)\n",
    "\n",
    "        #Metricas\n",
    "        \"\"\"\n",
    "        tn = Verdadeiro Negativo uma previs√£o correta prevista como benigno\n",
    "\n",
    "        fp = Falso Positivo um falso alarme um benigno previsto como malicioso\n",
    "\n",
    "        tp = Verdadeiro Positivo uma previs√£o correta (malicioso)\n",
    "\n",
    "        fn = Falso Negativo um r√≥tulo malicioso previsto como benigno\n",
    "\n",
    "        \"\"\"\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        elapsed = timeit.default_timer() - start_time\n",
    "       \n",
    "        print('SVM_SPR',elapsed, file=arquivo)\n",
    "        with open('MLDP/PIS_SPR/SVM_Resultados/metricas_PIS_SPR.txt', 'a') as arquivo1:\n",
    "            from sklearn import metrics \n",
    "            #Salva os resultados em um arquivo txt.\n",
    "            print('PIS incremento'+str(counter), file=arquivo1)\n",
    "            # Precis√£o do modelo: com que frequ√™ncia o classificador est√° correto?\n",
    "            print(\"Acur√°cia:\",metrics.accuracy_score(y_test, y_pred), file=arquivo1)\n",
    "            # Precis√£o do modelo: qual porcentagem de r√≥tulos positivos est√° correta?\n",
    "            print(\"Precis√£o:\",metrics.precision_score(y_test, y_pred), file=arquivo1)\n",
    "            # Model Recall: qual porcentagem de tuplas positivas s√£o rotuladas como tal?\n",
    "            print(\"Recall:\",metrics.recall_score(y_test, y_pred), file=arquivo1)\n",
    "            # \n",
    "            print(\"F1_Score:\",metrics.f1_score(y_test, y_pred), file=arquivo1)\n",
    "            # FPR: porcentagem de falso positivo de todos os negativos nos dados\n",
    "            print(\"FPR:\",fp/(fp+tn), file=arquivo1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRNR + SPR\n",
    "**Classifica√ß√£o de permiss√£o baseada em suporte (SPR): se o suporte de uma permiss√£o for muito\n",
    "baixo, n√£o ter√° muito impacto no desempenho da detec√ß√£o de malware.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_PRNR1.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cria um arquivo para cada incremento, fazer isso de 5 em 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ Permiss√µes:  5\n",
      "N¬∫ Permiss√µes:  10\n",
      "N¬∫ Permiss√µes:  15\n",
      "N¬∫ Permiss√µes:  20\n",
      "N¬∫ Permiss√µes:  25\n",
      "N¬∫ Permiss√µes:  30\n",
      "N¬∫ Permiss√µes:  35\n",
      "N¬∫ Permiss√µes:  40\n",
      "N¬∫ Permiss√µes:  45\n",
      "N¬∫ Permiss√µes:  50\n",
      "N¬∫ Permiss√µes:  55\n",
      "N¬∫ Permiss√µes:  60\n",
      "N¬∫ Permiss√µes:  65\n",
      "N¬∫ Permiss√µes:  70\n",
      "N¬∫ Permiss√µes:  75\n",
      "N¬∫ Permiss√µes:  80\n",
      "N¬∫ Permiss√µes:  85\n",
      "N¬∫ Permiss√µes:  90\n",
      "N¬∫ Permiss√µes:  95\n",
      "N¬∫ Permiss√µes:  100\n",
      "N¬∫ Permiss√µes:  105\n",
      "N¬∫ Permiss√µes:  108\n"
     ]
    }
   ],
   "source": [
    "#calcula a frequencia que cada permiss√£o possui\n",
    "soma = df_PRNR1.sum(axis=0)\n",
    "frequencia = soma.sort_values(ascending=False)\n",
    "#melhorar para quando o valor for impar ou par\n",
    "incremento=5\n",
    "while incremento < 115:\n",
    "    freq=frequencia.head(incremento)\n",
    "    with open(\"MLDP/PIS_SPR/PIS_SPR\"+str(incremento)+\".txt\",\"w\") as f:\n",
    "        concatenar =  np.concatenate((freq.index,'class'), axis=None)\n",
    "        wr = csv.writer(f,delimiter=\",\")\n",
    "        wr.writerow(concatenar)\n",
    "        \n",
    "    df_PRNR_txt = pd.read_csv('MLDP/PIS_SPR/PIS_SPR'+str(incremento)+'.txt')\n",
    "    df_filtrado2 = df_permi_drebim.reindex(columns=[*df_PRNR_txt])\n",
    "    df_PRNR=df_filtrado2.dropna(axis=1)\n",
    "    #cria o subset que sera testado usando svm\n",
    "    df_PRNR.to_csv(\"MLDP/PIS_SPR/PIS_SPR\"+str(incremento)+\".csv\", index=False)\n",
    "\n",
    "    df_PRNR.isna().values.any()\n",
    "    print('N¬∫ Permiss√µes: ',len(df_PRNR.columns)-1)  \n",
    "    incremento = incremento +5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter=5\n",
    "while counter < 115:\n",
    "    df_SPR = pd.read_csv('MLDP/PIS_SPR/PIS_SPR'+str(counter)+'.csv', encoding = 'utf8')\n",
    "    SVM(df_SPR,counter)\n",
    "    counter = counter +5         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](MLDP/PIS_SPR/SVM_Resultados/DesempenhoPRNR_SPR.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRNR + SPR + PMAR\n",
    "**aqui retiramos as permiss√µes que possuem associa√ß√£o (n√£o retiramos as duas, deixamos apenas 1 delas):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Aqui carregamos as permiss√µes extraidas no passo anterior\n",
    "PRNR_SPR = pd.read_csv(\"MLDP/PIS_SPR/PIS_SPR30.csv\", encoding = 'utf8')\n",
    "# -1 para n√£o considerar a coluna class\n",
    "len(PRNR_SPR.columns)-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PMAR\n",
    "**se os eventos A e B sempre co-ocorrem, √© altamente prov√°vel que\n",
    "esses dois eventos estejam associados. ent√£o excluimos a permiss√£o com menor relevancia**\n",
    "**Por exemplo, a permiss√£o WRITE SMS e a permiss√£o\n",
    "READ SMS s√£o sempre usadas juntas. Ambos tamb√©m pertencem √† lista\n",
    "de permiss√µes ‚Äúperigosas‚Äù do Google. Ainda assim, n√£o √© necess√°rio\n",
    "considerar ambas as permiss√µes, pois uma delas √© suficiente para\n",
    "caracterizar determinados comportamentos. Como resultado,\n",
    "podemos associar um, que tem um suporte maior, ao seu parceiro.Neste exemplo, podemos remover a permiss√£o WRITE SMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Processing 552 combinations | Sampling itemset size 2\n",
      "antecedents\n",
      "                              antecedents  \\\n",
      "0  (android.permission.CHANGE_WIFI_STATE)   \n",
      "1    (android.permission.MANAGE_ACCOUNTS)   \n",
      "2          (android.permission.WRITE_SMS)   \n",
      "\n",
      "                              consequents   support  confidence      lift  \n",
      "0  (android.permission.ACCESS_WIFI_STATE)  0.160758    0.993016  2.285669  \n",
      "1       (android.permission.GET_ACCOUNTS)  0.103359    0.992971  3.323536  \n",
      "2           (android.permission.READ_SMS)  0.111407    0.984136  5.269405  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from mlxtend.frequent_patterns import apriori, association_rules, fpmax, fpgrowth\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "## Read data from the csv file on local system.\n",
    "data_frame = PRNR_SPR.copy() \n",
    "\n",
    "features_name = data_frame.columns.values.tolist()\n",
    "\n",
    "class_apk = data_frame['class']\n",
    "\n",
    "features_dataset = data_frame.drop(['class'], axis=1)\n",
    "\n",
    "num_apk = features_dataset.shape[0] - 1\n",
    "num_features = features_dataset.shape[1]\n",
    "\n",
    "records = []\n",
    "for i in range(0,num_apk):\n",
    "    if class_apk[i] in [0, 1]:\n",
    "        i_list = []\n",
    "        for j in range(0,num_features):\n",
    "            if features_dataset.values[i][j] == 1:\n",
    "                i_list.append(features_name[j])\n",
    "        records.append(i_list) \n",
    "#print(records)\n",
    "\n",
    "te = TransactionEncoder()\n",
    "te_ary = te.fit(records).transform(records)\n",
    "df = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "#freq_items = apriori(df, min_support=0.1, use_colnames=True, low_memory=True, max_len =5, verbose=1)\n",
    "#freq_items = fpgrowth(df, min_support=0.2, use_colnames=True, max_len =3, verbose=1)\n",
    "freq_items = apriori(df, \n",
    "                    min_support=0.1,\n",
    "                    use_colnames=True,\n",
    "                    max_len =2,\n",
    "                    verbose=1)\n",
    "\n",
    "#print(freq_items)\n",
    "\n",
    "rules = association_rules(freq_items, metric=\"confidence\", min_threshold=0.965)\n",
    "#rules = association_rules(freq_items)\n",
    "\n",
    "rules = rules[(rules['lift'] >= 0.0)]\n",
    "rules_list = list(rules)\n",
    "print(rules_list[0])\n",
    "print(rules[['antecedents', 'consequents', 'support','confidence','lift']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N¬∫ de Permiss√µes 27\n"
     ]
    }
   ],
   "source": [
    "PRNR_SPR = pd.read_csv(\"MLDP/PIS_SPR/PIS_SPR30.csv\", encoding = 'utf8')\n",
    "PRNR_SPR_PMAR = PRNR_SPR.drop(columns=['android.permission.WRITE_SMS','android.permission.ACCESS_WIFI_STATE','android.permission.MANAGE_ACCOUNTS'])\n",
    "#subsetfinal\n",
    "PRNR_SPR_PMAR.to_csv(\"MLDP/PMAR/PRNR_SPR_PMAR.csv\", index=False)\n",
    "print('N¬∫ de Permiss√µes',len(PRNR_SPR_PMAR.columns)-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['android.permission.ACCESS_NETWORK_STATE',\n",
       "       'android.permission.WRITE_EXTERNAL_STORAGE',\n",
       "       'android.permission.READ_PHONE_STATE',\n",
       "       'android.permission.WAKE_LOCK',\n",
       "       'android.permission.RECEIVE_BOOT_COMPLETED',\n",
       "       'android.permission.VIBRATE', 'android.permission.GET_ACCOUNTS',\n",
       "       'android.permission.ACCESS_FINE_LOCATION',\n",
       "       'android.permission.ACCESS_COARSE_LOCATION',\n",
       "       'android.permission.SEND_SMS', 'android.permission.READ_CONTACTS',\n",
       "       'android.permission.RECEIVE_SMS', 'android.permission.READ_SMS',\n",
       "       'android.permission.GET_TASKS',\n",
       "       'android.permission.CHANGE_WIFI_STATE',\n",
       "       'android.permission.WRITE_SETTINGS', 'android.permission.CAMERA',\n",
       "       'android.permission.CALL_PHONE',\n",
       "       'android.permission.WRITE_CONTACTS',\n",
       "       'android.permission.READ_EXTERNAL_STORAGE',\n",
       "       'android.permission.USE_CREDENTIALS',\n",
       "       'com.android.browser.permission.READ_HISTORY_BOOKMARKS',\n",
       "       'android.permission.CHANGE_NETWORK_STATE',\n",
       "       'android.permission.RECORD_AUDIO',\n",
       "       'android.permission.READ_SYNC_SETTINGS',\n",
       "       'android.permission.RESTART_PACKAGES',\n",
       "       'android.permission.BLUETOOTH', 'class'], dtype=object)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PRNR_SPR_PMAR.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
